{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PhoneLevel_Autoencoder_MFCC_TrainL2_TestL2.ipynb","version":"0.3.2","provenance":[{"file_id":"1P7_uU4FSgccB1X4-x5xVyAkrM0Xt0rTn","timestamp":1551975809560},{"file_id":"1tU9msAU_Mq8R6GCBRgoZAph_2_gXe3Vu","timestamp":1548609256683},{"file_id":"1P90PoWrDm5O2YkZmI6GKpf7xa63cf7qD","timestamp":1548422095551}],"collapsed_sections":["aXoZguY5b02w","PlZoSV-eb03b","dMI1kHSOb037","JO9V8oEWb04T"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"R77w5oYLiAmk","colab_type":"code","outputId":"72a0a61f-e013-4563-8b8d-d4ac2b86623b","executionInfo":{"status":"ok","timestamp":1549361758234,"user_tz":-300,"elapsed":1411,"user":{"displayName":"Jawad Arshad","photoUrl":"https://lh5.googleusercontent.com/-4aOV1ZG2uVk/AAAAAAAAAAI/AAAAAAAAABw/DsyyNnGP7SM/s64/photo.jpg","userId":"13741434010255651176"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["pwd"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"]},"metadata":{"tags":[]},"execution_count":1}]},{"metadata":{"colab_type":"code","outputId":"9d492d4d-9577-4c97-f9b0-b7c2c2597a67","executionInfo":{"status":"ok","timestamp":1549361793780,"user_tz":-300,"elapsed":32083,"user":{"displayName":"Jawad Arshad","photoUrl":"https://lh5.googleusercontent.com/-4aOV1ZG2uVk/AAAAAAAAAAI/AAAAAAAAABw/DsyyNnGP7SM/s64/photo.jpg","userId":"13741434010255651176"}},"id":"d1eEVQxriiEp","colab":{"base_uri":"https://localhost:8080/","height":121}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('./drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at ./drive\n"],"name":"stdout"}]},{"metadata":{"id":"hC9IB51OznZN","colab_type":"code","outputId":"7ad5ffed-402f-4eb5-f9f8-bf9284010b78","executionInfo":{"status":"ok","timestamp":1549361803193,"user_tz":-300,"elapsed":5945,"user":{"displayName":"Jawad Arshad","photoUrl":"https://lh5.googleusercontent.com/-4aOV1ZG2uVk/AAAAAAAAAAI/AAAAAAAAABw/DsyyNnGP7SM/s64/photo.jpg","userId":"13741434010255651176"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"cell_type":"code","source":["!ls './drive/My Drive/Thesis Work'"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" CambridgeMonoPhoneDf.pickle\t      Implementation3.ipynb\n"," CambridgeWordFeaturesDf.pickle       Implementation4\n"," CheckScrapSpeed.ipynb\t\t      Implementation4.ipynb\n"," ConvertToWav.ipynb\t\t      L2monoPhoneDfTest.pickle\n","'Copy of l2arctic_release_v2.0.zip'   L2monoPhoneDfTrain.pickle\n"," DelIfCopiesFine.ipynb\t\t      L2WordFeaturesDfTest.pickle\n"," Implementation1\t\t      L2WordFeaturesDfTrain.pickle\n"," Implementation1.ipynb\t\t      MostCommon3000Oxford.txt\n"," Implementation2\t\t      UKpronunciations\n"," Implementation2.ipynb\t\t      USpronunciations\n"," Implementation3\n"],"name":"stdout"}]},{"metadata":{"id":"g2Osav3708xy","colab_type":"text"},"cell_type":"markdown","source":["Bism  \n","# Imports"]},{"metadata":{"id":"Nz23OfFgoMDo","colab_type":"code","outputId":"138926b1-1bd3-46bb-bcb0-6d2e562818b2","executionInfo":{"status":"ok","timestamp":1549718972486,"user_tz":-300,"elapsed":3511,"user":{"displayName":"Jawad Arshad","photoUrl":"https://lh5.googleusercontent.com/-4aOV1ZG2uVk/AAAAAAAAAAI/AAAAAAAAABw/DsyyNnGP7SM/s64/photo.jpg","userId":"13741434010255651176"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import os\n","import IPython.display as ipd\n","import librosa\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline\n","matplotlib.style.use('ggplot')\n","from tqdm import tqdm_notebook\n","\n","\n","#SKLEARN\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.preprocessing import LabelEncoder\n","import sklearn.metrics as sklm\n","from sklearn.manifold import TSNE\n","\n","#KERAS\n","from keras import models\n","from keras.models import Model, load_model\n","from keras import callbacks\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Input, Dense, Dropout, Flatten, BatchNormalization\n","from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose, AveragePooling2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.optimizers import SGD, Adam"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"colab_type":"text","id":"-1MAYCR6b02u"},"cell_type":"markdown","source":["# Implementation 4  (PHONE LEVEL)\n","## Using L2Training set\n","## L2 as val+test set"]},{"metadata":{"colab_type":"text","id":"SdjP405Hb02v"},"cell_type":"markdown","source":["### Training"]},{"metadata":{"colab_type":"text","id":"9uVHuupBb03r"},"cell_type":"markdown","source":["#### MODEL"]},{"metadata":{"colab_type":"code","id":"1-vlcC4Lb038","colab":{}},"cell_type":"code","source":["x_trainALL = np.load('./drive/My Drive/Thesis Work/Implementation4/x_train.npy')\n","train_phones = np.load('./drive/My Drive/Thesis Work/Implementation4/train_phones.npy')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8P94PR51Y0w5","colab_type":"code","outputId":"f11ce2bd-a9b2-4eab-c27d-b3b0a1392831","executionInfo":{"status":"ok","timestamp":1549361909295,"user_tz":-300,"elapsed":8261,"user":{"displayName":"Jawad Arshad","photoUrl":"https://lh5.googleusercontent.com/-4aOV1ZG2uVk/AAAAAAAAAAI/AAAAAAAAABw/DsyyNnGP7SM/s64/photo.jpg","userId":"13741434010255651176"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["train_phones.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(65113,)"]},"metadata":{"tags":[]},"execution_count":6}]},{"metadata":{"id":"wDGsRY3HNyjc","colab_type":"code","outputId":"4d7b24c1-f19e-48d3-e8cf-8e8a9ed15aa1","executionInfo":{"status":"ok","timestamp":1549362742033,"user_tz":-300,"elapsed":1199,"user":{"displayName":"Jawad Arshad","photoUrl":"https://lh5.googleusercontent.com/-4aOV1ZG2uVk/AAAAAAAAAAI/AAAAAAAAABw/DsyyNnGP7SM/s64/photo.jpg","userId":"13741434010255651176"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["x_trainALL.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(65113, 13, 50, 3)"]},"metadata":{"tags":[]},"execution_count":14}]},{"metadata":{"id":"RcnBZK3XcqgT","colab_type":"code","colab":{}},"cell_type":"code","source":["#commented to avoid accedental runs\n","'''for phone in set(train_phones):\n","  np.save(\"./drive/My Drive/Thesis Work/Implementation4/phone_means/mean_\"+phone+\".npy\",\\\n","          np.max(np.abs(x_train[train_phones == phone]),(0,1,2)))'''"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nunEjrDyhRZa","colab_type":"code","colab":{}},"cell_type":"code","source":["x_train = np.array([]).reshape(0,13,50,3)\n","for phone in list(set(train_phones)):\n","  train_max = np.load('./drive/My Drive/Thesis Work/Implementation4/phone_means/mean_'+phone+\".npy\")\n","  x_train = np.vstack((x_train,x_trainALL[train_phones == phone] / train_max))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NSR_aOY3Nl4f","colab_type":"code","outputId":"2838e459-1282-4424-cb29-48bd5442da63","executionInfo":{"status":"ok","timestamp":1549363487555,"user_tz":-300,"elapsed":1203,"user":{"displayName":"Jawad Arshad","photoUrl":"https://lh5.googleusercontent.com/-4aOV1ZG2uVk/AAAAAAAAAAI/AAAAAAAAABw/DsyyNnGP7SM/s64/photo.jpg","userId":"13741434010255651176"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["x_train.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(65113, 13, 50, 3)"]},"metadata":{"tags":[]},"execution_count":8}]},{"metadata":{"id":"g8NCYflaOwmU","colab_type":"code","outputId":"73d178bd-e06a-4ee4-efd0-6436b931106b","executionInfo":{"status":"ok","timestamp":1549364387877,"user_tz":-300,"elapsed":18474,"user":{"displayName":"Jawad Arshad","photoUrl":"https://lh5.googleusercontent.com/-4aOV1ZG2uVk/AAAAAAAAAAI/AAAAAAAAABw/DsyyNnGP7SM/s64/photo.jpg","userId":"13741434010255651176"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"cell_type":"code","source":["print(np.max(x_train))\n","print(np.min(x_train))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.9818808268950413\n","-1.0\n"],"name":"stdout"}]},{"metadata":{"id":"7u9ovJiBQumW","colab_type":"code","outputId":"9ba1471f-d008-46a0-cbbd-1d543dab4104","executionInfo":{"status":"ok","timestamp":1549364388936,"user_tz":-300,"elapsed":19313,"user":{"displayName":"Jawad Arshad","photoUrl":"https://lh5.googleusercontent.com/-4aOV1ZG2uVk/AAAAAAAAAAI/AAAAAAAAABw/DsyyNnGP7SM/s64/photo.jpg","userId":"13741434010255651176"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["np.nan in x_train"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"0B4BVYbskK6M","colab_type":"code","colab":{}},"cell_type":"code","source":["#together then alehda"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TpGhM5-pYImQ","colab_type":"code","outputId":"dc6fdfdc-06ff-4f82-d4d6-ba0867dbbb10","executionInfo":{"status":"ok","timestamp":1549364391211,"user_tz":-300,"elapsed":14817,"user":{"displayName":"Jawad Arshad","photoUrl":"https://lh5.googleusercontent.com/-4aOV1ZG2uVk/AAAAAAAAAAI/AAAAAAAAABw/DsyyNnGP7SM/s64/photo.jpg","userId":"13741434010255651176"}},"colab":{"base_uri":"https://localhost:8080/","height":87}},"cell_type":"code","source":["input_img = Input(shape=(13, 50, 3))  # adapt this if using `channels_first` image data format\n","\n","x = Conv2D(8, (2, 3), activation='tanh', padding='valid')(input_img)\n","x = MaxPooling2D((2, 2), padding='same')(x)\n","x = BatchNormalization()(x)\n","x = Conv2D(4, (3, 3), activation='tanh', padding='same')(x)\n","encoded = MaxPooling2D((2, 2), padding='same')(x)\n","\n","# at this point the representation is (3, 12, 32)\n","\n","x = BatchNormalization()(encoded)\n","x = Conv2D(4, (3, 3), activation='tanh', padding='same')(x)\n","x = UpSampling2D((2, 2))(x)\n","x = BatchNormalization()(x)\n","x = Conv2D(8, (3, 3), activation='tanh', padding='same')(x)\n","x = UpSampling2D((2, 2))(x)\n","x = BatchNormalization()(x)\n","decoded = Conv2DTranspose(3, (2, 3), activation='tanh', padding='valid')(x)\n","\n","autoencoder = Model(input_img, decoded)\n","\n","autoencoder.compile(optimizer= keras.optimizers.Adam(), loss='mean_squared_error');"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n"],"name":"stdout"}]},{"metadata":{"id":"puKPdi-KLQE0","colab_type":"code","outputId":"28693a6b-6ad6-44a3-d72e-a6b3ecaf1590","executionInfo":{"status":"ok","timestamp":1549364391212,"user_tz":-300,"elapsed":13936,"user":{"displayName":"Jawad Arshad","photoUrl":"https://lh5.googleusercontent.com/-4aOV1ZG2uVk/AAAAAAAAAAI/AAAAAAAAABw/DsyyNnGP7SM/s64/photo.jpg","userId":"13741434010255651176"}},"colab":{"base_uri":"https://localhost:8080/","height":605}},"cell_type":"code","source":["autoencoder.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 13, 50, 3)         0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 12, 48, 8)         152       \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 6, 24, 8)          0         \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 6, 24, 8)          32        \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 6, 24, 4)          292       \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 3, 12, 4)          0         \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 3, 12, 4)          16        \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 3, 12, 4)          148       \n","_________________________________________________________________\n","up_sampling2d_1 (UpSampling2 (None, 6, 24, 4)          0         \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 6, 24, 4)          16        \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 6, 24, 8)          296       \n","_________________________________________________________________\n","up_sampling2d_2 (UpSampling2 (None, 12, 48, 8)         0         \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 12, 48, 8)         32        \n","_________________________________________________________________\n","conv2d_transpose_1 (Conv2DTr (None, 13, 50, 3)         147       \n","=================================================================\n","Total params: 1,131\n","Trainable params: 1,083\n","Non-trainable params: 48\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"13yviC13LEPj","colab_type":"code","outputId":"edcbce99-f689-418b-d2ac-dbcba39cc83c","executionInfo":{"status":"ok","timestamp":1549368950897,"user_tz":-300,"elapsed":4571859,"user":{"displayName":"Jawad Arshad","photoUrl":"https://lh5.googleusercontent.com/-4aOV1ZG2uVk/AAAAAAAAAAI/AAAAAAAAABw/DsyyNnGP7SM/s64/photo.jpg","userId":"13741434010255651176"}},"colab":{"base_uri":"https://localhost:8080/","height":20264}},"cell_type":"code","source":["callbacklist=[callbacks.History(),callbacks.ModelCheckpoint('./jawadmodel.h5', monitor='loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=5)]\n","autoencoder.fit(x_train, x_train, batch_size=8192, epochs=500, callbacks=callbacklist)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/500\n","65113/65113 [==============================] - 13s 203us/step - loss: 0.4426\n","Epoch 2/500\n","65113/65113 [==============================] - 9s 136us/step - loss: 0.3388\n","Epoch 3/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.2682\n","Epoch 4/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.2119\n","Epoch 5/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.1634\n","\n","Epoch 00005: loss improved from inf to 0.16335, saving model to ./jawadmodel.h5\n","Epoch 6/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.1209\n","Epoch 7/500\n","65113/65113 [==============================] - 9s 135us/step - loss: 0.0863\n","Epoch 8/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0585\n","Epoch 9/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0398\n","Epoch 10/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0299\n","\n","Epoch 00010: loss improved from 0.16335 to 0.02986, saving model to ./jawadmodel.h5\n","Epoch 11/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0252\n","Epoch 12/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0223\n","Epoch 13/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0203\n","Epoch 14/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0187\n","Epoch 15/500\n","65113/65113 [==============================] - 9s 137us/step - loss: 0.0175\n","\n","Epoch 00015: loss improved from 0.02986 to 0.01747, saving model to ./jawadmodel.h5\n","Epoch 16/500\n","65113/65113 [==============================] - 9s 135us/step - loss: 0.0164\n","Epoch 17/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0155\n","Epoch 18/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0147\n","Epoch 19/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0140\n","Epoch 20/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0133\n","\n","Epoch 00020: loss improved from 0.01747 to 0.01332, saving model to ./jawadmodel.h5\n","Epoch 21/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0127\n","Epoch 22/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0122\n","Epoch 23/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0117\n","Epoch 24/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0113\n","Epoch 25/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0109\n","\n","Epoch 00025: loss improved from 0.01332 to 0.01087, saving model to ./jawadmodel.h5\n","Epoch 26/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0105\n","Epoch 27/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0102\n","Epoch 28/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0099\n","Epoch 29/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0096\n","Epoch 30/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0093\n","\n","Epoch 00030: loss improved from 0.01087 to 0.00933, saving model to ./jawadmodel.h5\n","Epoch 31/500\n","65113/65113 [==============================] - 9s 137us/step - loss: 0.0091\n","Epoch 32/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0089\n","Epoch 33/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0087\n","Epoch 34/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0085\n","Epoch 35/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0083\n","\n","Epoch 00035: loss improved from 0.00933 to 0.00831, saving model to ./jawadmodel.h5\n","Epoch 36/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0081\n","Epoch 37/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0080\n","Epoch 38/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0078\n","Epoch 39/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0077\n","Epoch 40/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0076\n","\n","Epoch 00040: loss improved from 0.00831 to 0.00757, saving model to ./jawadmodel.h5\n","Epoch 41/500\n","65113/65113 [==============================] - 9s 137us/step - loss: 0.0074\n","Epoch 42/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0073\n","Epoch 43/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0072\n","Epoch 44/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0071\n","Epoch 45/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0070\n","\n","Epoch 00045: loss improved from 0.00757 to 0.00699, saving model to ./jawadmodel.h5\n","Epoch 46/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0069\n","Epoch 47/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0068\n","Epoch 48/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0067\n","Epoch 49/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0066\n","Epoch 50/500\n","65113/65113 [==============================] - 9s 134us/step - loss: 0.0065\n","\n","Epoch 00050: loss improved from 0.00699 to 0.00652, saving model to ./jawadmodel.h5\n","Epoch 51/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0064\n","Epoch 52/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0064\n","Epoch 53/500\n","65113/65113 [==============================] - 9s 137us/step - loss: 0.0063\n","Epoch 54/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0062\n","Epoch 55/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0061\n","\n","Epoch 00055: loss improved from 0.00652 to 0.00612, saving model to ./jawadmodel.h5\n","Epoch 56/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0061\n","Epoch 57/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0060\n","Epoch 58/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0059\n","Epoch 59/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0058\n","Epoch 60/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0058\n","\n","Epoch 00060: loss improved from 0.00612 to 0.00579, saving model to ./jawadmodel.h5\n","Epoch 61/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0057\n","Epoch 62/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0057\n","Epoch 63/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0056\n","Epoch 64/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0056\n","Epoch 65/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0055\n","\n","Epoch 00065: loss improved from 0.00579 to 0.00550, saving model to ./jawadmodel.h5\n","Epoch 66/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0054\n","Epoch 67/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0054\n","Epoch 68/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0053\n","Epoch 69/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0053\n","Epoch 70/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0052\n","\n","Epoch 00070: loss improved from 0.00550 to 0.00525, saving model to ./jawadmodel.h5\n","Epoch 71/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0052\n","Epoch 72/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0052\n","Epoch 73/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0051\n","Epoch 74/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0051\n","Epoch 75/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0050\n","\n","Epoch 00075: loss improved from 0.00525 to 0.00503, saving model to ./jawadmodel.h5\n","Epoch 76/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0050\n","Epoch 77/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0050\n","Epoch 78/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0049\n","Epoch 79/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0049\n","Epoch 80/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0048\n","\n","Epoch 00080: loss improved from 0.00503 to 0.00484, saving model to ./jawadmodel.h5\n","Epoch 81/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0048\n","Epoch 82/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0048\n","Epoch 83/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0047\n","Epoch 84/500\n","65113/65113 [==============================] - 9s 135us/step - loss: 0.0047\n","Epoch 85/500\n","65113/65113 [==============================] - 9s 137us/step - loss: 0.0047\n","\n","Epoch 00085: loss improved from 0.00484 to 0.00468, saving model to ./jawadmodel.h5\n","Epoch 86/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0047\n","Epoch 87/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0046\n","Epoch 88/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0046\n","Epoch 89/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0046\n","Epoch 90/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0045\n","\n","Epoch 00090: loss improved from 0.00468 to 0.00454, saving model to ./jawadmodel.h5\n","Epoch 91/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0045\n","Epoch 92/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0045\n","Epoch 93/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0045\n","Epoch 94/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0044\n","Epoch 95/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0044\n","\n","Epoch 00095: loss improved from 0.00454 to 0.00440, saving model to ./jawadmodel.h5\n","Epoch 96/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0044\n","Epoch 97/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0044\n","Epoch 98/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0043\n","Epoch 99/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0043\n","Epoch 100/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0043\n","\n","Epoch 00100: loss improved from 0.00440 to 0.00428, saving model to ./jawadmodel.h5\n","Epoch 101/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0043\n","Epoch 102/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0042\n","Epoch 103/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0042\n","Epoch 104/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0042\n","Epoch 105/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0042\n","\n","Epoch 00105: loss improved from 0.00428 to 0.00417, saving model to ./jawadmodel.h5\n","Epoch 106/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0042\n","Epoch 107/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0041\n","Epoch 108/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0041\n","Epoch 109/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0041\n","Epoch 110/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0041\n","\n","Epoch 00110: loss improved from 0.00417 to 0.00407, saving model to ./jawadmodel.h5\n","Epoch 111/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0040\n","Epoch 112/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0040\n","Epoch 113/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0040\n","Epoch 114/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0040\n","Epoch 115/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0040\n","\n","Epoch 00115: loss improved from 0.00407 to 0.00397, saving model to ./jawadmodel.h5\n","Epoch 116/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0040\n","Epoch 117/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0039\n","Epoch 118/500\n","65113/65113 [==============================] - 9s 137us/step - loss: 0.0039\n","Epoch 119/500\n","65113/65113 [==============================] - 9s 137us/step - loss: 0.0039\n","Epoch 120/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0039\n","\n","Epoch 00120: loss improved from 0.00397 to 0.00388, saving model to ./jawadmodel.h5\n","Epoch 121/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0039\n","Epoch 122/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0038\n","Epoch 123/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0038\n","Epoch 124/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0038\n","Epoch 125/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0038\n","\n","Epoch 00125: loss improved from 0.00388 to 0.00379, saving model to ./jawadmodel.h5\n","Epoch 126/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0038\n","Epoch 127/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0038\n","Epoch 128/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0037\n","Epoch 129/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0037\n","Epoch 130/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0037\n","\n","Epoch 00130: loss improved from 0.00379 to 0.00370, saving model to ./jawadmodel.h5\n","Epoch 131/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0037\n","Epoch 132/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0037\n","Epoch 133/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0036\n","Epoch 134/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0036\n","Epoch 135/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0036\n","\n","Epoch 00135: loss improved from 0.00370 to 0.00362, saving model to ./jawadmodel.h5\n","Epoch 136/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0036\n","Epoch 137/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0036\n","Epoch 138/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0036\n","Epoch 139/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0036\n","Epoch 140/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0035\n","\n","Epoch 00140: loss improved from 0.00362 to 0.00353, saving model to ./jawadmodel.h5\n","Epoch 141/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0035\n","Epoch 142/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0035\n","Epoch 143/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0035\n","Epoch 144/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0035\n","Epoch 145/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0035\n","\n","Epoch 00145: loss improved from 0.00353 to 0.00345, saving model to ./jawadmodel.h5\n","Epoch 146/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0034\n","Epoch 147/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0034\n","Epoch 148/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0034\n","Epoch 149/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0034\n","Epoch 150/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0034\n","\n","Epoch 00150: loss improved from 0.00345 to 0.00337, saving model to ./jawadmodel.h5\n","Epoch 151/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0034\n","Epoch 152/500\n","65113/65113 [==============================] - 9s 137us/step - loss: 0.0033\n","Epoch 153/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0033\n","Epoch 154/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0033\n","Epoch 155/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0033\n","\n","Epoch 00155: loss improved from 0.00337 to 0.00330, saving model to ./jawadmodel.h5\n","Epoch 156/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0033\n","Epoch 157/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0033\n","Epoch 158/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0032\n","Epoch 159/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0032\n","Epoch 160/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0032\n","\n","Epoch 00160: loss improved from 0.00330 to 0.00322, saving model to ./jawadmodel.h5\n","Epoch 161/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0032\n","Epoch 162/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0032\n","Epoch 163/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0032\n","Epoch 164/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0032\n","Epoch 165/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0031\n","\n","Epoch 00165: loss improved from 0.00322 to 0.00314, saving model to ./jawadmodel.h5\n","Epoch 166/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0031\n","Epoch 167/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0031\n","Epoch 168/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0031\n","Epoch 169/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0031\n","Epoch 170/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0031\n","\n","Epoch 00170: loss improved from 0.00314 to 0.00306, saving model to ./jawadmodel.h5\n","Epoch 171/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0030\n","Epoch 172/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0030\n","Epoch 173/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0030\n","Epoch 174/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0030\n","Epoch 175/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0030\n","\n","Epoch 00175: loss improved from 0.00306 to 0.00299, saving model to ./jawadmodel.h5\n","Epoch 176/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0030\n","Epoch 177/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0030\n","Epoch 178/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0029\n","Epoch 179/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0029\n","Epoch 180/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0029\n","\n","Epoch 00180: loss improved from 0.00299 to 0.00292, saving model to ./jawadmodel.h5\n","Epoch 181/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0029\n","Epoch 182/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0029\n","Epoch 183/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0029\n","Epoch 184/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0029\n","Epoch 185/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0028\n","\n","Epoch 00185: loss improved from 0.00292 to 0.00285, saving model to ./jawadmodel.h5\n","Epoch 186/500\n","65113/65113 [==============================] - 9s 137us/step - loss: 0.0028\n","Epoch 187/500\n","65113/65113 [==============================] - 9s 137us/step - loss: 0.0028\n","Epoch 188/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0028\n","Epoch 189/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0028\n","Epoch 190/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0028\n","\n","Epoch 00190: loss improved from 0.00285 to 0.00278, saving model to ./jawadmodel.h5\n","Epoch 191/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0028\n","Epoch 192/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0028\n","Epoch 193/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0027\n","Epoch 194/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0027\n","Epoch 195/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0027\n","\n","Epoch 00195: loss improved from 0.00278 to 0.00271, saving model to ./jawadmodel.h5\n","Epoch 196/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0027\n","Epoch 197/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0027\n","Epoch 198/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0027\n","Epoch 199/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0027\n","Epoch 200/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0026\n","\n","Epoch 00200: loss improved from 0.00271 to 0.00265, saving model to ./jawadmodel.h5\n","Epoch 201/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0026\n","Epoch 202/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0026\n","Epoch 203/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0026\n","Epoch 204/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0026\n","Epoch 205/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0026\n","\n","Epoch 00205: loss improved from 0.00265 to 0.00259, saving model to ./jawadmodel.h5\n","Epoch 206/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0026\n","Epoch 207/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0026\n","Epoch 208/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0026\n","Epoch 209/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0025\n","Epoch 210/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0025\n","\n","Epoch 00210: loss improved from 0.00259 to 0.00253, saving model to ./jawadmodel.h5\n","Epoch 211/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0025\n","Epoch 212/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0025\n","Epoch 213/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0025\n","Epoch 214/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0025\n","Epoch 215/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0025\n","\n","Epoch 00215: loss improved from 0.00253 to 0.00248, saving model to ./jawadmodel.h5\n","Epoch 216/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0025\n","Epoch 217/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0025\n","Epoch 218/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0024\n","Epoch 219/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0024\n","Epoch 220/500\n","65113/65113 [==============================] - 9s 137us/step - loss: 0.0024\n","\n","Epoch 00220: loss improved from 0.00248 to 0.00243, saving model to ./jawadmodel.h5\n","Epoch 221/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0024\n","Epoch 222/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0024\n","Epoch 223/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0024\n","Epoch 224/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0024\n","Epoch 225/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0024\n","\n","Epoch 00225: loss improved from 0.00243 to 0.00238, saving model to ./jawadmodel.h5\n","Epoch 226/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0024\n","Epoch 227/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0024\n","Epoch 228/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0023\n","Epoch 229/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0023\n","Epoch 230/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0023\n","\n","Epoch 00230: loss improved from 0.00238 to 0.00233, saving model to ./jawadmodel.h5\n","Epoch 231/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0023\n","Epoch 232/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0023\n","Epoch 233/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0023\n","Epoch 234/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0023\n","Epoch 235/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0023\n","\n","Epoch 00235: loss improved from 0.00233 to 0.00229, saving model to ./jawadmodel.h5\n","Epoch 236/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0023\n","Epoch 237/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0023\n","Epoch 238/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0023\n","Epoch 239/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0023\n","Epoch 240/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0022\n","\n","Epoch 00240: loss improved from 0.00229 to 0.00224, saving model to ./jawadmodel.h5\n","Epoch 241/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0022\n","Epoch 242/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0022\n","Epoch 243/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0022\n","Epoch 244/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0022\n","Epoch 245/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0022\n","\n","Epoch 00245: loss improved from 0.00224 to 0.00220, saving model to ./jawadmodel.h5\n","Epoch 246/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0022\n","Epoch 247/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0022\n","Epoch 248/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0022\n","Epoch 249/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0022\n","Epoch 250/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0022\n","\n","Epoch 00250: loss improved from 0.00220 to 0.00217, saving model to ./jawadmodel.h5\n","Epoch 251/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0022\n","Epoch 252/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0022\n","Epoch 253/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0021\n","Epoch 254/500\n","65113/65113 [==============================] - 9s 137us/step - loss: 0.0021\n","Epoch 255/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0021\n","\n","Epoch 00255: loss improved from 0.00217 to 0.00213, saving model to ./jawadmodel.h5\n","Epoch 256/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0021\n","Epoch 257/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0021\n","Epoch 258/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0021\n","Epoch 259/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0021\n","Epoch 260/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0021\n","\n","Epoch 00260: loss improved from 0.00213 to 0.00210, saving model to ./jawadmodel.h5\n","Epoch 261/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0021\n","Epoch 262/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0021\n","Epoch 263/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0021\n","Epoch 264/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0021\n","Epoch 265/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0021\n","\n","Epoch 00265: loss improved from 0.00210 to 0.00206, saving model to ./jawadmodel.h5\n","Epoch 266/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0021\n","Epoch 267/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0021\n","Epoch 268/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0020\n","Epoch 269/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0020\n","Epoch 270/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0020\n","\n","Epoch 00270: loss improved from 0.00206 to 0.00203, saving model to ./jawadmodel.h5\n","Epoch 271/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0020\n","Epoch 272/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0020\n","Epoch 273/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0020\n","Epoch 274/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0020\n","Epoch 275/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0020\n","\n","Epoch 00275: loss improved from 0.00203 to 0.00200, saving model to ./jawadmodel.h5\n","Epoch 276/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0020\n","Epoch 277/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0020\n","Epoch 278/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0020\n","Epoch 279/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0020\n","Epoch 280/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0020\n","\n","Epoch 00280: loss improved from 0.00200 to 0.00198, saving model to ./jawadmodel.h5\n","Epoch 281/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0020\n","Epoch 282/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0020\n","Epoch 283/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0020\n","Epoch 284/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0020\n","Epoch 285/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0019\n","\n","Epoch 00285: loss improved from 0.00198 to 0.00195, saving model to ./jawadmodel.h5\n","Epoch 286/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0019\n","Epoch 287/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0019\n","Epoch 288/500\n","65113/65113 [==============================] - 9s 137us/step - loss: 0.0019\n","Epoch 289/500\n","65113/65113 [==============================] - 9s 137us/step - loss: 0.0019\n","Epoch 290/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0019\n","\n","Epoch 00290: loss improved from 0.00195 to 0.00192, saving model to ./jawadmodel.h5\n","Epoch 291/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0019\n","Epoch 292/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0019\n","Epoch 293/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0019\n","Epoch 294/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0019\n","Epoch 295/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0019\n","\n","Epoch 00295: loss improved from 0.00192 to 0.00190, saving model to ./jawadmodel.h5\n","Epoch 296/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0019\n","Epoch 297/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0019\n","Epoch 298/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0019\n","Epoch 299/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0019\n","Epoch 300/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0019\n","\n","Epoch 00300: loss improved from 0.00190 to 0.00187, saving model to ./jawadmodel.h5\n","Epoch 301/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0019\n","Epoch 302/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0019\n","Epoch 303/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0019\n","Epoch 304/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0019\n","Epoch 305/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0018\n","\n","Epoch 00305: loss improved from 0.00187 to 0.00185, saving model to ./jawadmodel.h5\n","Epoch 306/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0018\n","Epoch 307/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0018\n","Epoch 308/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0018\n","Epoch 309/500\n","65113/65113 [==============================] - 9s 137us/step - loss: 0.0018\n","Epoch 310/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0018\n","\n","Epoch 00310: loss improved from 0.00185 to 0.00182, saving model to ./jawadmodel.h5\n","Epoch 311/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0018\n","Epoch 312/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0018\n","Epoch 313/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0018\n","Epoch 314/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0018\n","Epoch 315/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0018\n","\n","Epoch 00315: loss improved from 0.00182 to 0.00180, saving model to ./jawadmodel.h5\n","Epoch 316/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0018\n","Epoch 317/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0018\n","Epoch 318/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0018\n","Epoch 319/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0018\n","Epoch 320/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0018\n","\n","Epoch 00320: loss improved from 0.00180 to 0.00177, saving model to ./jawadmodel.h5\n","Epoch 321/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0018\n","Epoch 322/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0018\n","Epoch 323/500\n","65113/65113 [==============================] - 9s 137us/step - loss: 0.0018\n","Epoch 324/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0018\n","Epoch 325/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0018\n","\n","Epoch 00325: loss improved from 0.00177 to 0.00175, saving model to ./jawadmodel.h5\n","Epoch 326/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0017\n","Epoch 327/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0017\n","Epoch 328/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0017\n","Epoch 329/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0017\n","Epoch 330/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0017\n","\n","Epoch 00330: loss improved from 0.00175 to 0.00173, saving model to ./jawadmodel.h5\n","Epoch 331/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0017\n","Epoch 332/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0017\n","Epoch 333/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0017\n","Epoch 334/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0017\n","Epoch 335/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0017\n","\n","Epoch 00335: loss improved from 0.00173 to 0.00170, saving model to ./jawadmodel.h5\n","Epoch 336/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0017\n","Epoch 337/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0017\n","Epoch 338/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0017\n","Epoch 339/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0017\n","Epoch 340/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0017\n","\n","Epoch 00340: loss improved from 0.00170 to 0.00168, saving model to ./jawadmodel.h5\n","Epoch 341/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0017\n","Epoch 342/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0017\n","Epoch 343/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0017\n","Epoch 344/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0017\n","Epoch 345/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0017\n","\n","Epoch 00345: loss improved from 0.00168 to 0.00166, saving model to ./jawadmodel.h5\n","Epoch 346/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0017\n","Epoch 347/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0017\n","Epoch 348/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0016\n","Epoch 349/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0016\n","Epoch 350/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0016\n","\n","Epoch 00350: loss improved from 0.00166 to 0.00164, saving model to ./jawadmodel.h5\n","Epoch 351/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0016\n","Epoch 352/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0016\n","Epoch 353/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0016\n","Epoch 354/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0016\n","Epoch 355/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0016\n","\n","Epoch 00355: loss improved from 0.00164 to 0.00162, saving model to ./jawadmodel.h5\n","Epoch 356/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0016\n","Epoch 357/500\n","65113/65113 [==============================] - 9s 136us/step - loss: 0.0016\n","Epoch 358/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0016\n","Epoch 359/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0016\n","Epoch 360/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0016\n","\n","Epoch 00360: loss improved from 0.00162 to 0.00160, saving model to ./jawadmodel.h5\n","Epoch 361/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0016\n","Epoch 362/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0016\n","Epoch 363/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0016\n","Epoch 364/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0016\n","Epoch 365/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0016\n","\n","Epoch 00365: loss improved from 0.00160 to 0.00157, saving model to ./jawadmodel.h5\n","Epoch 366/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0016\n","Epoch 367/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0016\n","Epoch 368/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0016\n","Epoch 369/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0016\n","Epoch 370/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0016\n","\n","Epoch 00370: loss improved from 0.00157 to 0.00155, saving model to ./jawadmodel.h5\n","Epoch 371/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0016\n","Epoch 372/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0015\n","Epoch 373/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0015\n","Epoch 374/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0015\n","Epoch 375/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0015\n","\n","Epoch 00375: loss improved from 0.00155 to 0.00153, saving model to ./jawadmodel.h5\n","Epoch 376/500\n","65113/65113 [==============================] - 9s 137us/step - loss: 0.0015\n","Epoch 377/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0015\n","Epoch 378/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0015\n","Epoch 379/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0015\n","Epoch 380/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0015\n","\n","Epoch 00380: loss improved from 0.00153 to 0.00151, saving model to ./jawadmodel.h5\n","Epoch 381/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0015\n","Epoch 382/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0015\n","Epoch 383/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0015\n","Epoch 384/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0015\n","Epoch 385/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0015\n","\n","Epoch 00385: loss improved from 0.00151 to 0.00149, saving model to ./jawadmodel.h5\n","Epoch 386/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0015\n","Epoch 387/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0015\n","Epoch 388/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0015\n","Epoch 389/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0015\n","Epoch 390/500\n","65113/65113 [==============================] - 9s 137us/step - loss: 0.0015\n","\n","Epoch 00390: loss improved from 0.00149 to 0.00147, saving model to ./jawadmodel.h5\n","Epoch 391/500\n","65113/65113 [==============================] - 9s 137us/step - loss: 0.0015\n","Epoch 392/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0015\n","Epoch 393/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0015\n","Epoch 394/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0015\n","Epoch 395/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0015\n","\n","Epoch 00395: loss improved from 0.00147 to 0.00146, saving model to ./jawadmodel.h5\n","Epoch 396/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0015\n","Epoch 397/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0014\n","Epoch 398/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0014\n","Epoch 399/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0014\n","Epoch 400/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0014\n","\n","Epoch 00400: loss improved from 0.00146 to 0.00144, saving model to ./jawadmodel.h5\n","Epoch 401/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0014\n","Epoch 402/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0014\n","Epoch 403/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0014\n","Epoch 404/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0014\n","Epoch 405/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0014\n","\n","Epoch 00405: loss improved from 0.00144 to 0.00142, saving model to ./jawadmodel.h5\n","Epoch 406/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0014\n","Epoch 407/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0014\n","Epoch 408/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0014\n","Epoch 409/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0014\n","Epoch 410/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0014\n","\n","Epoch 00410: loss improved from 0.00142 to 0.00140, saving model to ./jawadmodel.h5\n","Epoch 411/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0014\n","Epoch 412/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0014\n","Epoch 413/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0014\n","Epoch 414/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0014\n","Epoch 415/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0014\n","\n","Epoch 00415: loss improved from 0.00140 to 0.00138, saving model to ./jawadmodel.h5\n","Epoch 416/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0014\n","Epoch 417/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0014\n","Epoch 418/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0014\n","Epoch 419/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0014\n","Epoch 420/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0014\n","\n","Epoch 00420: loss improved from 0.00138 to 0.00137, saving model to ./jawadmodel.h5\n","Epoch 421/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0014\n","Epoch 422/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0014\n","Epoch 423/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0014\n","Epoch 424/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0014\n","Epoch 425/500\n","65113/65113 [==============================] - 9s 136us/step - loss: 0.0014\n","\n","Epoch 00425: loss improved from 0.00137 to 0.00135, saving model to ./jawadmodel.h5\n","Epoch 426/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0013\n","Epoch 427/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0013\n","Epoch 428/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0013\n","Epoch 429/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0013\n","Epoch 430/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0013\n","\n","Epoch 00430: loss improved from 0.00135 to 0.00133, saving model to ./jawadmodel.h5\n","Epoch 431/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0013\n","Epoch 432/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0013\n","Epoch 433/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0013\n","Epoch 434/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0013\n","Epoch 435/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0013\n","\n","Epoch 00435: loss improved from 0.00133 to 0.00132, saving model to ./jawadmodel.h5\n","Epoch 436/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0013\n","Epoch 437/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0013\n","Epoch 438/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0013\n","Epoch 439/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0013\n","Epoch 440/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0013\n","\n","Epoch 00440: loss improved from 0.00132 to 0.00130, saving model to ./jawadmodel.h5\n","Epoch 441/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0013\n","Epoch 442/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0013\n","Epoch 443/500\n","65113/65113 [==============================] - 9s 137us/step - loss: 0.0013\n","Epoch 444/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0013\n","Epoch 445/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0013\n","\n","Epoch 00445: loss improved from 0.00130 to 0.00129, saving model to ./jawadmodel.h5\n","Epoch 446/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0013\n","Epoch 447/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0013\n","Epoch 448/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0013\n","Epoch 449/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0013\n","Epoch 450/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0013\n","\n","Epoch 00450: loss improved from 0.00129 to 0.00127, saving model to ./jawadmodel.h5\n","Epoch 451/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0013\n","Epoch 452/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0013\n","Epoch 453/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0013\n","Epoch 454/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0013\n","Epoch 455/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0013\n","\n","Epoch 00455: loss improved from 0.00127 to 0.00126, saving model to ./jawadmodel.h5\n","Epoch 456/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0013\n","Epoch 457/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0013\n","Epoch 458/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0013\n","Epoch 459/500\n","65113/65113 [==============================] - 9s 137us/step - loss: 0.0012\n","Epoch 460/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0012\n","\n","Epoch 00460: loss improved from 0.00126 to 0.00124, saving model to ./jawadmodel.h5\n","Epoch 461/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0012\n","Epoch 462/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0012\n","Epoch 463/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0012\n","Epoch 464/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0012\n","Epoch 465/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0012\n","\n","Epoch 00465: loss improved from 0.00124 to 0.00123, saving model to ./jawadmodel.h5\n","Epoch 466/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0012\n","Epoch 467/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0012\n","Epoch 468/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0012\n","Epoch 469/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0012\n","Epoch 470/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0012\n","\n","Epoch 00470: loss improved from 0.00123 to 0.00122, saving model to ./jawadmodel.h5\n","Epoch 471/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0012\n","Epoch 472/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0012\n","Epoch 473/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0012\n","Epoch 474/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0012\n","Epoch 475/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0012\n","\n","Epoch 00475: loss improved from 0.00122 to 0.00121, saving model to ./jawadmodel.h5\n","Epoch 476/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0012\n","Epoch 477/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0012\n","Epoch 478/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0012\n","Epoch 479/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0012\n","Epoch 480/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0012\n","\n","Epoch 00480: loss improved from 0.00121 to 0.00119, saving model to ./jawadmodel.h5\n","Epoch 481/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0012\n","Epoch 482/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0012\n","Epoch 483/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0012\n","Epoch 484/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0012\n","Epoch 485/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0012\n","\n","Epoch 00485: loss improved from 0.00119 to 0.00118, saving model to ./jawadmodel.h5\n","Epoch 486/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0012\n","Epoch 487/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0012\n","Epoch 488/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0012\n","Epoch 489/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0012\n","Epoch 490/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0012\n","\n","Epoch 00490: loss improved from 0.00118 to 0.00117, saving model to ./jawadmodel.h5\n","Epoch 491/500\n","65113/65113 [==============================] - 9s 139us/step - loss: 0.0012\n","Epoch 492/500\n","65113/65113 [==============================] - 9s 138us/step - loss: 0.0012\n","Epoch 493/500\n","65113/65113 [==============================] - 9s 135us/step - loss: 0.0012\n","Epoch 494/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0012\n","Epoch 495/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0012\n","\n","Epoch 00495: loss improved from 0.00117 to 0.00116, saving model to ./jawadmodel.h5\n","Epoch 496/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0012\n","Epoch 497/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0012\n","Epoch 498/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0012\n","Epoch 499/500\n","65113/65113 [==============================] - 9s 141us/step - loss: 0.0011\n","Epoch 500/500\n","65113/65113 [==============================] - 9s 140us/step - loss: 0.0011\n","\n","Epoch 00500: loss improved from 0.00116 to 0.00115, saving model to ./jawadmodel.h5\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f3b1c9699e8>"]},"metadata":{"tags":[]},"execution_count":8}]},{"metadata":{"id":"GjKD1mDybdML","colab_type":"code","colab":{}},"cell_type":"code","source":["!cp ./jawadmodel.h5 \"./drive/My Drive/Thesis Work/Implementation4/autoencoderModelALL.h5\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"a61j9kabpO5-","colab_type":"text"},"cell_type":"markdown","source":["### Testing"]},{"metadata":{"id":"85Vd8wtMpris","colab_type":"code","outputId":"f2f7b7cc-e08e-443f-f0ef-f66401af5b18","executionInfo":{"status":"ok","timestamp":1549370071435,"user_tz":-300,"elapsed":5562,"user":{"displayName":"Jawad Arshad","photoUrl":"https://lh5.googleusercontent.com/-4aOV1ZG2uVk/AAAAAAAAAAI/AAAAAAAAABw/DsyyNnGP7SM/s64/photo.jpg","userId":"13741434010255651176"}},"colab":{"base_uri":"https://localhost:8080/","height":67}},"cell_type":"code","source":["!ls './drive/My Drive/Thesis Work/Implementation4'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["autoencoderModelALL.h5\ttest_labels.npy       train_phones.npy\ty_train.npy\n","model.h5\t\ttest_phones.npy       x_test.npy\n","phone_means\t\ttest_typeOfError.npy  x_train.npy\n"],"name":"stdout"}]},{"metadata":{"id":"SaWG8DAbppI8","colab_type":"code","colab":{}},"cell_type":"code","source":["x_testALL = np.load('./drive/My Drive/Thesis Work/Implementation4/x_test.npy')\n","test_phones = np.load('./drive/My Drive/Thesis Work/Implementation4/test_phones.npy')\n","test_labelsALL = np.load('./drive/My Drive/Thesis Work/Implementation4/test_labels.npy')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DlPiwxDppXQ7","colab_type":"code","colab":{}},"cell_type":"code","source":["#MAX normalization\n","x_test = np.array([]).reshape(0,13,50,3)\n","test_labels = np.array([]).reshape(0,1)\n","for phone in set(test_phones).intersection(set(train_phones)):\n","  train_max = np.load('./drive/My Drive/Thesis Work/Implementation4/phone_means/mean_'+phone+\".npy\")\n","  x_test = np.vstack((x_test,x_testALL[test_phones == phone] / train_max))\n","  test_labels = np.vstack((test_labels, test_labelsALL[test_phones == phone].reshape(-1,1)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Jv_9D3aQ2m7s","colab_type":"code","colab":{}},"cell_type":"code","source":["test_labels = test_labels.reshape(-1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BuHiIpCVpovT","colab_type":"code","outputId":"d2cc86ed-5d57-4511-d7bf-09cb0552077c","executionInfo":{"status":"ok","timestamp":1549374973732,"user_tz":-300,"elapsed":1295,"user":{"displayName":"Jawad Arshad","photoUrl":"https://lh5.googleusercontent.com/-4aOV1ZG2uVk/AAAAAAAAAAI/AAAAAAAAABw/DsyyNnGP7SM/s64/photo.jpg","userId":"13741434010255651176"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["x_test.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(34795, 13, 50, 3)"]},"metadata":{"tags":[]},"execution_count":84}]},{"metadata":{"id":"0VZvGQgS742L","colab_type":"code","colab":{}},"cell_type":"code","source":["shuffledIndexes = np.random.permutation(range(x_test.shape[0]))\n","x_test = x_test[shuffledIndexes]\n","test_labels = test_labels[shuffledIndexes]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rhLtSECVrVMp","colab_type":"code","outputId":"09d07745-9c46-4361-d961-edbb1e901c65","executionInfo":{"status":"ok","timestamp":1549375489419,"user_tz":-300,"elapsed":64052,"user":{"displayName":"Jawad Arshad","photoUrl":"https://lh5.googleusercontent.com/-4aOV1ZG2uVk/AAAAAAAAAAI/AAAAAAAAABw/DsyyNnGP7SM/s64/photo.jpg","userId":"13741434010255651176"}},"colab":{"base_uri":"https://localhost:8080/","height":67}},"cell_type":"code","source":["validationSetLength = 6000 #initial 6000 from test as validation set\n","accs = []\n","f1mis = []\n","\n","for threshold in [0.0010,0.00105,0.00120,0.00125,0.00130]:\n","  predictions = [1 if autoencoder.evaluate(x_test[i:i+1],x_test[i:i+1],verbose=0)<=threshold\\\n","   else 0 for i in range(validationSetLength)]\n","  \n","  accs.append(sklm.accuracy_score(test_labels[:validationSetLength],predictions))\n","  f1mis.append(sklm.precision_recall_fscore_support(test_labels[:validationSetLength],predictions)[2][0])\n","\n","print(\"Threshold: \", np.argmax(f1mis))\n","print(\"Max Achievable Accuracy: \", accs[np.argmax(f1mis)])\n","print(\"Max Achievable F-1 score for Mispronunciations: \", max(f1mis))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Threshold:  1\n","Max Achievable Accuracy:  0.4558333333333333\n","Max Achievable F-1 score for Mispronunciations:  0.20886842742912526\n"],"name":"stdout"}]},{"metadata":{"id":"Ic6v9u2U-fyZ","colab_type":"code","colab":{}},"cell_type":"code","source":["validationSetLength = 6000 #initial 6000 from test as validation set\n","threshold = 0.00105\n","\n","predictions = [1 if autoencoder.evaluate(x_test[i:i+1],x_test[i:i+1],verbose=0)<=threshold\\\n"," else 0 for i in range(validationSetLength,x_test.shape[0])] "],"execution_count":0,"outputs":[]},{"metadata":{"id":"ll0eA34Drw7I","colab_type":"code","outputId":"3fd7702b-f9ca-46a0-89f1-e6a270da1301","executionInfo":{"status":"ok","timestamp":1549375679178,"user_tz":-300,"elapsed":1200,"user":{"displayName":"Jawad Arshad","photoUrl":"https://lh5.googleusercontent.com/-4aOV1ZG2uVk/AAAAAAAAAAI/AAAAAAAAABw/DsyyNnGP7SM/s64/photo.jpg","userId":"13741434010255651176"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["print('Accuracy = ', sklm.accuracy_score(test_labels[validationSetLength:],predictions))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy =  0.4498003125542629\n"],"name":"stdout"}]},{"metadata":{"id":"uw5K1qGI7MQT","colab_type":"code","outputId":"5748bf7b-edea-464c-98ca-4a3802097323","executionInfo":{"status":"ok","timestamp":1549375691044,"user_tz":-300,"elapsed":1680,"user":{"displayName":"Jawad Arshad","photoUrl":"https://lh5.googleusercontent.com/-4aOV1ZG2uVk/AAAAAAAAAAI/AAAAAAAAABw/DsyyNnGP7SM/s64/photo.jpg","userId":"13741434010255651176"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"cell_type":"code","source":["sklm.precision_recall_fscore_support(test_labels[validationSetLength:],predictions) #0 - 1"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([0.12207055, 0.89312852]),\n"," array([0.60708922, 0.42923899]),\n"," array([0.2032688, 0.579817 ]),\n"," array([ 3329, 25466]))"]},"metadata":{"tags":[]},"execution_count":96}]},{"metadata":{"id":"wFdv0NChPY55","colab_type":"text"},"cell_type":"markdown","source":["If a voice is substituted by another then combined autoencoder will reconstruct it also as trained on that also so combined is not working AH"]}]}